OLLAMA LOCAL DOCUMENTS WEB INTERFACE WITH GRADIO 

requirements:
gradio
chardet
fitz
json
os
requests

** First run OLLAMA with local LLM
 ollama run (llm)

** Then run main.py

This is a work in progress
